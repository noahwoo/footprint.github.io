
## In context learning

- Survey
    - **A Survey on In-context Learning, 2023, PKU** (OK)
- Explanations:
    - **Rethinking the Role of Demonstrations: What Makes In-Context LearningWork?, 2022, Facebook**
    - **An Explanation of In-context Learning as Implicit Bayesian Inference, 2022, Stanford**
    - **[How does in-context learning work? A framework for understanding the differences from traditional supervised learning](https://ai.stanford.edu/blog/understanding-incontext/), 2022, Stanford**
        - In one word: 
        - In context learning as a Bayesian inference of the prompt concept that every example in the prompt shares: $z$ in $P(z|p)$
        - Methods
        - Pretraining distribution: assume LLM fits the pretraining distribution exactly
        - Prompt distribution: In context prompt examples are drawn from the same prompt concept
        - Bayesian inference for in context learning formally:
            - $P(o|p) = \int_{z} P(o|p,z) P(z|p) dz$, $p$ for prompts, $z$ for latent concept, $o$ output of LLM
            - $P(z|p)$ concentrates on the prompt concept with more examples in the prompt 
            - Noise and signal
                - Training prompt examples privide signal: Strong enough to overwrite the noise
                - Transition between examples in low prob.: unnatural text, different from the pretraining distribution
                - In-context learning robust to noise
        - Empirical evidence
            - Forming the prompt with the ground truth output is not required to achieve good in-context learning performance
            - The underlying input distribution that examples are drawn matters
            - The set of outputs in the task and input-output format matter
            - One more evidence: In-context learning performance is highly correlated with term frequencies during pretraining
        - Avenues for extensions
            - Input-output ground truth mapping matters for synthetic tasks
            - Instruction as improving Bayesian inference by providing explicit observations of the latent prompt concept
            - Preference of pretraining data for eliciting in-context learning
    - **What Can Transformers Learn In-Context? A Case Study of Simple Function Classes, 2023, Stanford**
    - **Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers, 2022, Tsinghua**
    - **Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer, 2023, MetaAI**
      - In one word: analyze SGD training dynamics, for 1-layer position encoding free transformer with one self-attention plus one decoder layer on next token prediction task
      - Methods
        - 
      - Conclusion
        - self-attention as *discriminative scanning algorithm*
          - **Discriminative Bias**: attends more to tokens distinct for next token, less to common ones
          - **Frequency Bias**: drop attention weight of keys from low to high co-occurrence with query in training set
          - no collapse to one-hot attention due to a phase transition(similar to Induction Head)